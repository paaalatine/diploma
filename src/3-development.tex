\mysection{ОПИСАНИЕ ПРОЦЕССА РАЗРАБОТКИ ПРОГРАММЫ}
\

Программа прдставляет собой набор модулей на языке Python. Далее будет описан процесс разработки каждого из модулей программы.

\

\subsection{Модуль обучения}
\

Модуль обучения представлен классом на языке Python, который содержит метод для загрузки корпуса данных, метод, в котором происходит преобразование данных корпуса, построение и обучение модели, а также метод сохранения обученной модели на диск.

Для преобразования набора обучающих данных в массив векторов используется класс библиотеки Scikit-learn CountVectorizer. Он принимает в качестве аргумента конструктора разделитель, производит токенизацию всех документов коллекции, на этой основе составляет словарь токенов коллекции и конвертирует все документы в вектора, содержащие количество вхождений токена в каждый документ. 

В данном классе также реализован метод для загрузки обучающей коллекции средствами библиотеки pandas. В листинге 3.2 представлен пример построения объекта CountVectorizer и перехода к векторам.

\lstinputlisting[
  caption={Использование CountVectorizer},
  label={lst:modules__events__short}
]{src/vectorizer.py}
\

Для нормализации значений векторов был использован класс той же библиотеки TfidfTransformer. Он преобразовывает значения в каждом векторе коллекции согласно статической мере TF-IDF, используя значения, которые были установлены объектом класса CountVectorizer. В листинге 3.3 представлено построение объекта TfidfTransformer и нормализация значений векторов.

\lstinputlisting[
  caption={Использование TfidfTransformer},
  label={lst:modules__events__short}
]{src/transformer.py}
\

Выбранный для классификации алгоритм машины опорных векторов в библиотеке Scikit-learn реализован классом LinearSVC\cite{Scikit}. Поддерживает мультиклассовую классификацию по схеме one-vs-the-rest. В листинге 3.4 показан вызов метода класса LinearSVC, с помощью которого строится классификатор.

\lstinputlisting[
  caption={Использование LinearSVC},
  label={lst:modules__events__short}
]{src/classifier.py}
\

Одним из параментров конструктора LinearSVC является метод регуляризации. Была выбрана регуляризация через манхэттенское расстояние или $L_{1}$, так как в этом случае была достигнута наибольшая точность. Регуляризация — метод добавления некоторых дополнительных ограничений к условию с целью предотвратить переобучение. То есть, если в процессе обучения в получающихся многочленах слишком большие коэффициенты, к модели применяется штраф.

\
$$L_{1} = \sum_{i}(y_{i} - y(t_{i}))^2 + \lambda\sum_{i}a_{i}^2$$\normalsize

Все объекты указаных классов являются полями класса модуля обучения и создаются с необходимыми параметрами в его контрукторе.

В соответствии с функциональными требованиями в данном модуле был создан метод для сохранения объектов CountVectorizer, TfidfTransformer и LinearSVC на диск. Внутри него был использован метод \textbf{dump} (value, file-
\
name), который принадлежит библиотеке Joblib\cite{Joblib}.

\newpage

\subsection{Модуль классификации}
\

Модуль классификации, как и модуль обучения, является классом на языке Python. Этот модуль предназначен для загрузки с диска обученного классификатора и использование этого классификатора для предсказаний. 

Возможность загрузки с диска обученной модели — одно из функциональных требований. В методе, представляющем этот функционал, использовался метод \textbf{load} (filename), принадлежащий библиотеке Joblib\cite{Joblib}.

Еще одним функциональным требованием к программе являлось то, что программа не должна находить связь, если в запросе был указан товар, который не существует в базе клиента. Для реализации этого механизма было положено, что слова, которые ни разу не встречались в корпусе данных, будут иметь отрицательный вес. Это основывается на предположении, что все слова, которые не являются "важными" словами, то есть идентификационными номерами или названиями моделей, уже встречались в коллекции документов, на которой был обучен классификатор, и занесены в словарь. Номера и названия, которые содержатся в документах обучающей коллекции, являются "важными" и также занесены в словарь. Если же слово не содержится в словаре, оно не часто употребляемое в рамках данного корпуса, соответственно, является важным элементом документа, который необходимо классифицировать. Но связи с такими документами не должны быть найдены, поэтому все слова входного документа проверяются на наличие их в словаре и, если они отсутсвуют, им выставляется отрицательный вес.

\lstinputlisting[
  caption={Предсказание},
  label={lst:modules__events__short}
]{src/prediction.py}
\

После обработки входных данных проиходит классификация с помощью метода класса LinearSVC \textbf{predict} (self, X), который принимает один или несколько векторов и возвращает соответствующие метки класса. В листинге 3.5 представлен фрагмент кода, отражающий этот процесс. Помимо получения метки класса извлекается вероятность данного предсказания, чтобы оценить его точность. Это делается с помощью метода класса LinearSVC \textbf{decision\_function} (self, X), который возвращает расстояние от векторов X до гиперплоскостей для каждого возможного класса. Далее из всех этих расстояний выбирается расстояние до предсказанного класса, после чего в соответствии с функцией предсказания расстояние преобразовывается в вероятность.

\newpage


\subsection{Модуль API}
\

Модуль API это небольшое приложение с использованием Flask. В листинге 3.6 представлена обработка GET-запроса по адресу "/search", параметром "q" которого является строка-документ, который необходимо классифицировать. 

\lstinputlisting[
  caption={Пример обработки запроса},
  label={lst:modules__events__short}
]{src/api.py}
\

Код, который обрабатывает запрос, обращается к методу модуля классификации \textbf{predict}, это происходит после загрузки обученной модели с диска. После классификации клиент получает ответ в формате JSON, содержащий метку класса и точность данного предсказания.

\newpage
